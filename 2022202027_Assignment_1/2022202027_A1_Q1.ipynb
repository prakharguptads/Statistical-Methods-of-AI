{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSd3vc8oPt3b"
      },
      "source": [
        "# Assignment 1\n",
        "## Question `1` (K-Nearest Neighbour)\n",
        "\n",
        "| | |\n",
        "|-|-|\n",
        "| Course | Statistical Methods in AI |\n",
        "| Release Date | `19.01.2023` |\n",
        "| Due Date | `29.01.2023` |\n",
        "\n",
        "### Instructions:\n",
        "1.   Assignment must be implemented using python notebook only (Colab , VsCode , Jupyter etc.)\n",
        "2.   You are allowed to use libraries for data preprocessing (numpy, pandas, nltk etc) and for algorithms as well (sklearn etc). You are not however allowed to directly use classifier models.\n",
        "3.   The performance of the model will hold weightage but you will also be graded largely for data preprocessing steps , explanations , feature selection for vectors etc.\n",
        "4.   Strict plagiarism checking will be done. An F will be awarded for plagiarism.\n",
        "\n",
        "### The Dataset\n",
        "The dataset is avaible in the zip file which is a collection of *11099 tweets*. The data will be in the form of a csv file. The ground truth is also given in the zip file which corresponds to whether a tweet was popular or not. Since the task involves selecting features yourself to vectorize a tweet , we suggest some data analysis of the columns you consider important.\n",
        "<br><br>\n",
        "\n",
        "### The Task\n",
        "You have to build a classifier which can predict the popularity of the tweet, i.e , if the tweet was popular or not. You are required to use **KNN** algorithm to build the classifier and cannot use any inbuilt classifier. All columns are supposed to be analyzed , filtered and preprocessed to determine its importance as a feature in the vector for every tweet (Not every column will be useful).<br>\n",
        "The Data contains the **raw text of the tweet**(in the text column) as well as other **meta data** like likes count , user followers count. Note that it might be useful to **create new columns** with useful information. For example, *number of hashtags* might be useful but is not directly present as a column.<br>\n",
        "There are 3 main sub parts:\n",
        "1. *Vectorize tweets using only meta data* - likes , user followers count , and other created data\n",
        "2. *Vectorize tweets using only it's text*. This segment will require NLP techniques to clean the text and extract a vector using a BoW model. Here is a useful link for the same - [Tf-Idf](https://towardsdatascience.com/text-vectorization-term-frequency-inverse-document-frequency-tfidf-5a3f9604da6d). Since these vectors will be very large , we recommend reducing their dimensinality (~10 - 25). Hint: [Dimentionality Reduction](https://jonathan-hui.medium.com/machine-learning-singular-value-decomposition-svd-principal-component-analysis-pca-1d45e885e491). Please note that for this also you are allowed to use libraries.\n",
        "\n",
        "3. *Combining the vectors from above two techinques to create one bigger vector*\n",
        "<br>\n",
        "\n",
        "\n",
        "Using KNN on these vectors build a classifier to predict the popularity of the tweet and report accuracies on each of the three methods as well as analysis. You can use sklearn's Nearest Neighbors and need not write KNN from scratch. (However you cannot use the classifier directly). You are expected to try the classifier for different number of neighbors and identify the optimal K value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LJvylX8680U"
      },
      "source": [
        "## Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UrD1GJ6-YA5M"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn import *\n",
        "import nltk\n",
        "from sklearn import datasets\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.feature_selection import SelectPercentile, chi2\n",
        "from scipy.stats import mode\n",
        "import numpy as np\n",
        "import matplotlib as mp\n",
        "from sklearn.model_selection import train_test_split\n",
        "import json\n",
        "import io\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neighbors import NearestNeighbors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoakVIVW7EOT"
      },
      "source": [
        "## Load and display the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YRwXxW4WwEL8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "929b7af7-216d-498c-cfd3-378a247de9c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 11099 entries, 0 to 11098\n",
            "Data columns (total 21 columns):\n",
            " #   Column                 Non-Null Count  Dtype  \n",
            "---  ------                 --------------  -----  \n",
            " 0   created_at             11099 non-null  object \n",
            " 1   id                     11099 non-null  float64\n",
            " 2   id_str                 11099 non-null  float64\n",
            " 3   text                   11099 non-null  object \n",
            " 4   truncated              11099 non-null  bool   \n",
            " 5   entities               11099 non-null  object \n",
            " 6   metadata               11099 non-null  object \n",
            " 7   source                 11099 non-null  object \n",
            " 8   is_quote_status        11099 non-null  bool   \n",
            " 9   retweet_count          11099 non-null  int64  \n",
            " 10  favorite_count         11099 non-null  int64  \n",
            " 11  lang                   11099 non-null  object \n",
            " 12  user_name              11099 non-null  object \n",
            " 13  user_screen_name       11099 non-null  object \n",
            " 14  user_followers_count   11099 non-null  int64  \n",
            " 15  user_friends_count     11099 non-null  int64  \n",
            " 16  user_listed_count      11099 non-null  int64  \n",
            " 17  user_created_at        11099 non-null  object \n",
            " 18  user_favourites_count  11099 non-null  int64  \n",
            " 19  user_verified          11099 non-null  bool   \n",
            " 20  user_statuses_count    11099 non-null  int64  \n",
            "dtypes: bool(3), float64(2), int64(7), object(9)\n",
            "memory usage: 1.6+ MB\n"
          ]
        }
      ],
      "source": [
        "#your code here\n",
        "pdDf1 = pd.read_csv('ground_truth.csv')\n",
        "df = pd.read_csv('Tweets.csv')\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywNXO3TpwQkV"
      },
      "source": [
        "## Exploratory Data Analysis\n",
        "*This is an ungraded section but is recommended to get a good grasp on the dataset*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Nl8EwC77wqX4"
      },
      "outputs": [],
      "source": [
        "# your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mztyk9Kew7q1"
      },
      "source": [
        "## Part-1\n",
        "*Vectorize tweets using only meta data*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "y-rDkUtVxQph"
      },
      "outputs": [],
      "source": [
        "def get_features():\n",
        "  \"\"\"\n",
        "  Funtion to return a matrix of dimensions (number of tweets, number of chosen features)\n",
        "  Input parameters to this funcion are to be chosen as per requirement (Example: Loaded dataframe of the dataset) \n",
        "  \"\"\"\n",
        "\n",
        "  # your code here\n",
        "  df = pd.read_csv('Tweets.csv')\n",
        "  df1 = df\n",
        "  df1.drop(['created_at', 'id','is_quote_status', 'id_str', 'text', 'truncated', 'entities', 'metadata', 'source', 'lang', 'user_name', 'user_screen_name', 'user_verified', 'user_created_at'], axis=1, inplace=True)\n",
        "  return df1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4K7Fzh5Q4wrV"
      },
      "source": [
        "Perform KNN using the vector obtained from get_features() function. Following are the steps to be followed:\n",
        "1. Normalise the vectors\n",
        "2. Split the data into training and test to estimate the performance.\n",
        "3. Fit the Nearest Neughbiurs module to the training data and obtain the predicted class by getting the nearest neighbours on the test data.\n",
        "4. Report the accuracy, chosen k-value and method used to obtain the predicted class. Hint: Plot accuracies for a range of k-values. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class K_Nearest_Neighbors_Classifier() : \n",
        "      \n",
        "    def __init__( self, K ) :\n",
        "          \n",
        "        self.K = K\n",
        "          \n",
        "    # Function to store training set\n",
        "          \n",
        "    def fit( self, X_train, Y_train ) :\n",
        "          \n",
        "        self.X_train = X_train\n",
        "          \n",
        "        self.Y_train = Y_train\n",
        "          \n",
        "        # no_of_training_examples, no_of_features\n",
        "          \n",
        "        self.m, self.n = X_train.shape\n",
        "      \n",
        "    # Function for prediction\n",
        "          \n",
        "    def predict( self, X_test ) :\n",
        "          \n",
        "        self.X_test = X_test\n",
        "          \n",
        "        # no_of_test_examples, no_of_features\n",
        "          \n",
        "        self.m_test, self.n = X_test.shape\n",
        "          \n",
        "        # initialize Y_predict\n",
        "          \n",
        "        Y_predict = np.zeros( self.m_test )\n",
        "          \n",
        "        for i in range( self.m_test ) :\n",
        "              \n",
        "            x = self.X_test[i]\n",
        "              \n",
        "            # find the K nearest neighbors from current test example\n",
        "              \n",
        "            neighbors = np.zeros( self.K )\n",
        "              \n",
        "            neighbors = self.find_neighbors( x )\n",
        "              \n",
        "            # most frequent class in K neighbors\n",
        "              \n",
        "            Y_predict[i] = mode( neighbors )[0][0]    \n",
        "              \n",
        "        return Y_predict\n",
        "      \n",
        "    # Function to find the K nearest neighbors to current test example\n",
        "            \n",
        "    def find_neighbors( self, x ) :\n",
        "          \n",
        "        # calculate all the euclidean distances between current \n",
        "        # test example x and training set X_train\n",
        "          \n",
        "        euclidean_distances = np.zeros( self.m )\n",
        "          \n",
        "        for i in range( self.m ) :\n",
        "              \n",
        "            d = self.euclidean( x, self.X_train[i] )\n",
        "              \n",
        "            euclidean_distances[i] = d\n",
        "          \n",
        "        # sort Y_train according to euclidean_distance_array and \n",
        "        # store into Y_train_sorted\n",
        "          \n",
        "        inds = euclidean_distances.argsort()\n",
        "          \n",
        "        Y_train_sorted = self.Y_train[inds]\n",
        "          \n",
        "        return Y_train_sorted[:self.K]\n",
        "      \n",
        "    # Function to calculate euclidean distance\n",
        "              \n",
        "    def euclidean( self, x, x_train ) :\n",
        "          \n",
        "        return np.sqrt( np.sum( np.square( x - x_train ) ) )"
      ],
      "metadata": {
        "id": "WqFwCIyaBlEE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = get_features()\n",
        "df=pd.DataFrame(preprocessing.normalize(df,norm='l2', axis=1))\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "hNX27mgPCt7K",
        "outputId": "7b128fea-e97a-4e35-b165-450ce60dd58e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              0    1         2         3         4         5         6\n",
              "0      0.002485  0.0  0.003364  0.005805  0.000154  0.725275  0.688422\n",
              "1      0.067276  0.0  0.008891  0.004354  0.000137  0.075780  0.994803\n",
              "2      0.548672  0.0  0.037360  0.036041  0.000147  0.794952  0.253605\n",
              "3      0.001383  0.0  0.334497  0.335741  0.000553  0.828706  0.297715\n",
              "4      0.595977  0.0  0.007395  0.017004  0.000165  0.148017  0.789024\n",
              "...         ...  ...       ...       ...       ...       ...       ...\n",
              "11094  0.000063  0.0  0.010097  0.017034  0.000088  0.996459  0.081719\n",
              "11095  0.836143  0.0  0.042739  0.059675  0.001195  0.202137  0.504595\n",
              "11096  0.000000  0.0  0.031622  0.022019  0.000000  0.021082  0.999035\n",
              "11097  0.000862  0.0  0.024187  0.011638  0.000383  0.758123  0.651558\n",
              "11098  0.000000  0.0  0.025285  0.047499  0.000214  0.004571  0.998541\n",
              "\n",
              "[11099 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d48c10fd-37e7-4411-9b89-28aeff00281b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.002485</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003364</td>\n",
              "      <td>0.005805</td>\n",
              "      <td>0.000154</td>\n",
              "      <td>0.725275</td>\n",
              "      <td>0.688422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.067276</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008891</td>\n",
              "      <td>0.004354</td>\n",
              "      <td>0.000137</td>\n",
              "      <td>0.075780</td>\n",
              "      <td>0.994803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.548672</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.037360</td>\n",
              "      <td>0.036041</td>\n",
              "      <td>0.000147</td>\n",
              "      <td>0.794952</td>\n",
              "      <td>0.253605</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.001383</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.334497</td>\n",
              "      <td>0.335741</td>\n",
              "      <td>0.000553</td>\n",
              "      <td>0.828706</td>\n",
              "      <td>0.297715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.595977</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.007395</td>\n",
              "      <td>0.017004</td>\n",
              "      <td>0.000165</td>\n",
              "      <td>0.148017</td>\n",
              "      <td>0.789024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11094</th>\n",
              "      <td>0.000063</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.010097</td>\n",
              "      <td>0.017034</td>\n",
              "      <td>0.000088</td>\n",
              "      <td>0.996459</td>\n",
              "      <td>0.081719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11095</th>\n",
              "      <td>0.836143</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.042739</td>\n",
              "      <td>0.059675</td>\n",
              "      <td>0.001195</td>\n",
              "      <td>0.202137</td>\n",
              "      <td>0.504595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11096</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.031622</td>\n",
              "      <td>0.022019</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.021082</td>\n",
              "      <td>0.999035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11097</th>\n",
              "      <td>0.000862</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.024187</td>\n",
              "      <td>0.011638</td>\n",
              "      <td>0.000383</td>\n",
              "      <td>0.758123</td>\n",
              "      <td>0.651558</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11098</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.025285</td>\n",
              "      <td>0.047499</td>\n",
              "      <td>0.000214</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>0.998541</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11099 rows Ã— 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d48c10fd-37e7-4411-9b89-28aeff00281b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d48c10fd-37e7-4411-9b89-28aeff00281b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d48c10fd-37e7-4411-9b89-28aeff00281b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "EBHGbdsi4fe-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80239c40-6d8c-4e51-b7ac-60d3e021ce8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neighbors/_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on test set by our model       :   93.86486486486486\n",
            "Accuracy on test set by sklearn model   :   93.86486486486486\n"
          ]
        }
      ],
      "source": [
        "# your code here\n",
        "X = df.iloc[:,:].values\n",
        "Y = pdDf1.iloc[:,-1:].values\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 1/3, random_state = 0 )\n",
        "model = K_Nearest_Neighbors_Classifier( K = 3 )\n",
        "model.fit( X_train, Y_train )\n",
        "model1 = KNeighborsClassifier( n_neighbors = 3 )\n",
        "model1.fit( X_train, Y_train )\n",
        "Y_pred = model.predict( X_test )\n",
        "Y_pred1 = model1.predict( X_test )\n",
        "correctly_classified = 0\n",
        "correctly_classified1 = 0\n",
        "count = 0\n",
        "for count in range( np.size( Y_pred ) ) :\n",
        "    if Y_test[count] == Y_pred[count] :\n",
        "        correctly_classified = correctly_classified + 1\n",
        "    if Y_test[count] == Y_pred1[count] :\n",
        "        correctly_classified1 = correctly_classified1 + 1\n",
        "    count = count + 1\n",
        "print( \"Accuracy on test set by our model       :  \", (correctly_classified / count ) * 100 )\n",
        "print( \"Accuracy on test set by sklearn model   :  \", (correctly_classified1 / count ) * 100 )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k_val = [2,3,5,8,11,15]\n",
        "accu = []\n",
        "for i in k_val:\n",
        "  model = K_Nearest_Neighbors_Classifier( K = i )\n",
        "  model.fit( X_train, Y_train )\n",
        "  Y_pred = model.predict( X_test )\n",
        "  correctly_classified = 0\n",
        "  count = 0\n",
        "  for count in range( np.size( Y_pred ) ) :\n",
        "      if Y_test[count] == Y_pred[count] :\n",
        "          correctly_classified = correctly_classified + 1\n",
        "      count = count + 1\n",
        "  print( \"Accuracy on test set by our model       :  \", (correctly_classified / count ) * 100 )\n",
        "  accu.append((correctly_classified / count ) * 100)\n",
        "print(accu)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7l0Q0qTd-lz",
        "outputId": "c668137e-5957-418f-e722-1a97275b4714"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on test set by our model       :   93.43243243243244\n",
            "Accuracy on test set by our model       :   93.86486486486486\n",
            "Accuracy on test set by our model       :   94.21621621621622\n",
            "Accuracy on test set by our model       :   94.1891891891892\n",
            "Accuracy on test set by our model       :   94.48648648648648\n",
            "Accuracy on test set by our model       :   94.72972972972973\n",
            "[93.43243243243244, 93.86486486486486, 94.21621621621622, 94.1891891891892, 94.48648648648648, 94.72972972972973]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt \n",
        "plt.plot(k_val, accu) \n",
        "# naming the x axis \n",
        "plt.xlabel('x - axis') \n",
        "# naming the y axis \n",
        "plt.ylabel('y - axis') \n",
        "plt.yticks(list(range(91, 96, 1)))\n",
        "    \n",
        "# function to show the plot \n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "u6CTRJ_VeRU-",
        "outputId": "06947485-9904-460a-ee0d-90a557fa16bc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEKCAYAAAAVaT4rAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAavElEQVR4nO3deXRed53f8fdHkjfJmyzvi6SQxXbiSWJbWSELYcsEN4EwzIE422Eg5UyAhGaaU4Yp7ZSBIUAHphNgSOIApyOYlgTKACUNzXACpRMltnGCg0NCiS3vtmzJsiRb67d/3CtFVrw8sn31WLqf1zk+z/Pc9fv4SJ/70+/e+7uKCMzMLD9Kil2AmZmNLAe/mVnOOPjNzHLGwW9mljMOfjOznHHwm5nlTKbBL+keSRslvSjp3nTaf5S0XdKG9N8NWdZgZmZHKstqw5KWAR8CLgW6gCck/Sid/aWI+GJW+zYzs2PLLPiBpUBDRHQASHoauDnD/ZmZWQGU1Z27kpYCPwCuAA4BTwFrgX3AnUBr+vm+iGg+yvp3AXcBVFRUrFyyZEkmdZqZjVXr1q1riohZQ6dnFvwAkv4E+FOgHXgR6AT+GmgCAvg0MC8iPnC87dTV1cXatWszq9PMbCyStC4i6oZOz/TkbkSsiYiVEXE10Ay8HBG7I6I3IvqAh0nOAZiZ2QjJ+qqe2elrNUn//rclzRu0yLuBjVnWYGZmR8ry5C7A45KqgG7g7ohokfR3ki4m6erZDPzrjGswM7NBMg3+iLjqKNNuy3KfZmZ2fL5z18wsZxz8ZmY54+A3M8sZB7+ZWc44+M3McsbBb2aWMw5+M7OccfCbmeVM1nfumplZAbp7+9jefIjN+9rZsq9j4PX+6xezZO7U07ovB7+Z2Qjp6ulja3MHW/a1s7kpfU1DflvzIXr7XhstuXx8KTVVFbQe6jntdTj4zcxOo8PdvWzd38Hmff3BnrTcX21qZ0fLIQZlO5MnlFE7s5xlC6ax6sJ51FRVUFtVQW1VObOmTEBSJjU6+M3MhulQVy9b9h/Zak9a8e3sbD3M4MecTJ1YxlkzK1hRXcnNyxck4T6znNqqCmZUjM8s3I/HwW9mdhRtnT1sGdzf3pS8bt7Xzu7WziOWnVExnpqqci57QxU1VUmo11SVc9bMCqaXjy/SNzg2B7+Z5Vbr4e6BQB/ccn+1qYOmtiPDfebkCdRWlfOmc2ZRW1VOzcykS6amqoJpk8YV6RucHAe/mY1pLR1dg7piXut337yvg/3tXUcsO2fqBGqqKrhuyayB/vaaqnJqZ1YwecLYicux803MLJcigv3tg8J90OvmpnYOHOo+Yvn50yZSU1XBOy6Yk4Z70mqvqSqnfHw+IjEf39LMRrWIYG9bZ9Lf3nTkde6b97Vz8PBrlzxKsGD6JGqrKlh14bwj+tsXzShn4rjSIn6TM4OD38zOCBHB7tbO1/W393fPtHf1DixbWiIWVk6ipqqC5dXTj2i5L5oxiQllDvfjcfCb2Yjp6wt2th5mS1P7665z37yvncPdfQPLlpWI6hnl1FSVc+lZMwZOqJ5VVcGCykmMK/WIMyfLwW9mp1VvX7Cj5dDACdTBIb9lfwddPa+F+/jSEqqryqmtKueN58wcaLWfNbOCedMmUuZwz4SD38yGrae3j+0th3j1KP3tW/d30N372h1ME8pKqE3D/M1LZg9c5147s4K5UydSWjLyNzDlnYPfzI6pty/47a6DrGts5ne7Dw603Lc1H6LnKOPKLJ4zhbefP5fa9BLI2qoKZk+ZQInD/Yzi4DezAe2dPWzY2sLazc2s3bKfDY0tHOxMrpjpH1fmggXTeGc6rsxZM5MrZmZNzm5cGTv9HPxmObaj5RDrtjSzbksS9Jt2HqS3L5Bg8Zwp3HjxfOpqK1lZPYNFMyY53McIB79ZTvT2BZt2tqYh38y6zfvZceAwAJPGlXLxoun86bVns7KmkuXVlaNuGAIrnIPfbIxq6+zhV43NrN2ctOh/1dg8cC383KkTWVlbyQerK6mrrWTpvKm+PDJHHPxmY0BEsD3ttukP+pd2tdIXyZ2sS+ZO5eYVC5Num5pKFkx3t02eOfjNRqGe3j427TzI2i37026bZna1Jt025eNLWV49nY9cdy51NZUsr57OlInutrHXOPjNRoHWw92s39LM+rR/fsPWFjrSbpv50yZyyVkzqKtJWvNL5k7xjU92XA5+szNMRLCt+VDSmk+7bX67+yARUCJYOm8q7125kJW1SdjPnz6p2CXbKOPgNyuy7t4+frOjNemyScN+z8HkISCTJ5SxvHo61y+bS13NDC6unj6mxoW34vBPkNkIO9DRzfrG5oEW/fPbWgYGJ1swfRJXnF2VdtvMYPHcKR7SwE47B79ZhiKCxv0d6Z2wSYv+5d1tQDK08PnzpvK+S6qpq62krmYGc6dNLHLFlgcOfrPTqKunj407DiQnYdOw739265SJZayormTVhfOpq6nkokXTqXC3jRWBf+rMTkFLR9egO2GTbpvOdNjhRTMmcdW5M1lZk9wkde5sd9vYmcHBb1agiGDzvg7Wbt4/EPa/25N025SViAvmT2X1ZTVpt00ls6e628bOTA7+nNlz8DDfXbuNn720B4CyUjGutIRxpSWUlYhxZSWMKxFl6bRx6fyyUjGupOS19wPTk+X7p49Ppw28T7c1/gTr9ddwJrWIO3t62bj9wECXzfotzexr7wJg6sQyVtZU8u7lC1hZU8lFC6czabwf92ejg4M/ByKCf/n9PuobGvlfG3fR0xdcvGg65eNL6ekNDnb30NPXR09v0NWbvPb09tHVG0Om9zFoCPZMSCQHgSEHn4GDQ0kJ48pEWUnJCQ4igw44AwcfHfeg1H/T04s7DrBuczMvbD8w8LSomqpyrlk8i7qaGdTVVnLOrMkeY95GLQf/GHago5vH1m+jvmELv9/bzrRJ47jzylref1k1Z8+afFLb7O0Lunv76OkLunv66E4PDN29fXSnB4runhgyfdD7vuSg0r/8wLx0vZ6+wdOT5bt70v0N3lb//nv76OjqHbKPITX176uvjyjgwDWuVCxbMI07rqhhZU0lK2oqmT3F3TY2djj4x5iIYMPWFuobGvnh8zvo7OljefV0/vN7L+KdF85j4rhT644oLRGlJek2JpyGgkdY79ADyJCDUW9f0ro/1f8nszOZg3+MaO/s4QcbdlDfsIUXd7RSMb6UP1q5kFsuq+aC+dOKXd4Zo//A5WC3PHPwj3Iv7Wql/plGvv+r7bR19rBk7hT+6l3LeNfyBb6138yOyskwCh3u7uUnG3dS/0wja7c0M76shFUXzmP1ZTWsqJ7ucdbN7Lgc/KPI5qZ2vv1sI99du5Xmjm7OmlnBX7xzKe9ZsZDKivHFLs/MRgkH/xmuu7ePpzbtpr6hkV+80kRpiXj7+XO49fIarnhDlS8pNLNhc/CfoXa0HOIfn9vKf3uukd2tncyfNpH73nYef3zJIub4jlAzOwWZBr+ke4APAQIejogvD5p3H/BFYFZENGVZx2jR1xf8/JW91Dc08tSm3QRw7Xmz+My7arh28Sw/VcnMTovMgl/SMpLQvxToAp6Q9KOI+J2kRcDbgcas9j+aNLV18t212/j2s1vYuv8QMyeP58PXnM37L61m0YzyYpdnZmNMli3+pUBDRHQASHoauBn4PPAl4H7gBxnu/4wWETz76n7qGxr5ycaddPcGl501g/vfsYR3XDCX8WVu3ZtZNrIM/o3AZyRVAYeAG4C1km4CtkfE88e77FDSXcBdANXV1RmWObJaD3fzvXXbqG9o5JU9bUyZWMbqy2q49fJqzpk9pdjlmVkOZBb8EbFJ0gPAk0A7sIHkJv8/J+nmOdH6DwEPAdTV1WU8NFj2XtjWQv0zjfzT8zs41N3LRQun8fn3XMi/umi+R3U0sxGV6cndiFgDrAGQ9FlgN/AuoL+1vxBYL+nSiNiVZS3F0NHVww+f30F9QyMvbDvApHGl3HTxfFZfVsMfLPQwCmZWHFlf1TM7IvZIqibp3788Iv520PzNQN1Yu6rnld0HqW9o5PH12zh4uIfz5kzmL2+8gHevWMDUieOKXZ6Z5VzW1/E/nvbxdwN3R0RLxvsrms6eXp7YuIv6hkaefXU/40tL+MM/mMutl9dQV1PpYRTM7IyRdVfPVSeYX5vl/kdC476OgWEU9rV3UT2jnE/84RL+aOVCqiaPwnGLzWzM8527J6mprZP7H3uBn/12DwLeujQZRuFN58z0MApmdkZz8J+EprZO3v/QM2xt7uBj153L+y5dxLxpk4pdlplZQRz8w9TU1sktDyeh/407L+WKs6uKXZKZ2bD49tBh2NfWyeqHG2jc38Gjd17i0DezUcnBX6B9bZ3c8nADW/a38+gdl3Dl2TOLXZKZ2Ulx8BdgX1snqx9pYPO+dtbccQlXnuPQN7PRy8F/Avvbu1j9SAOvNrXz6J2X8EaHvpmNcg7+49jf3sUtDz/Dq01JS9+hb2ZjgYP/GJoHtfQfuaOON53r0DezscGXcx5Fc3sXtzzSwP/b28Yjt9dx1bmzil2Smdlp4xb/EP0t/f7Qv/o8h76ZjS0O/kFaOrq4dU0Dv9vbxsMOfTMboxz8qZaOpKX/yp42HrptJdc49M1sjHLwAwc6url1TQOv7E5C/9rFs4tdkplZZnIf/P2h//KuNr5+u0PfzMa+XAf/gUPd3PZoA7/ddZCv37aSNzv0zSwHchv8Bw51c9uaBl7aeZC/v20Fb17i0DezfMhl8B841M3taxrYtLOVr926guuWzCl2SWZmIyZ3wd96uJvbH32W3+xs5WurV/KWpQ59M8uXXAV/6+FublvzLL/ZcYCvrl7JW8936JtZ/uQm+FsPd3N7GvpfuWUFb3Pom1lO5SL4Dx7u5o5Hn2Xj9iT0337B3GKXZGZWNGM++A+mffq/3naAr6x26JuZjeng72/p/3rbAR68ZQXvcOibmY3t4P/UD17khW0HePCW5Vy/zKFvZgZjfDz++69fzKoL5/mSTTOzQcZ08M+bNol50yYVuwwzszPKmO7qMTOz13Pwm5nljIPfzCxnHPxmZjnj4Dczy5kTBr+kCkkl6fvzJN0oaVz2pZmZWRYKafH/HJgoaQHwJHAb8M0sizIzs+wUEvyKiA7gZuCrEfFe4IJsyzIzs6wUFPySrgBWAz9Op5VmV5KZmWWpkOC/F/gE8P2IeFHSG4CfZVuWmZll5YRDNkTE08DTgz7/HvhYlkWZmVl2jhn8kr4cEfdK+iEQQ+dHxI2ZVmZmZpk4Xov/v6avXxyJQszMbGQcM/gjYl36dlNE7Bk8T9LiTKsyM7PMFHJy9xeS/rj/g6T7gO9nV5KZmWWpkPH4rwUekvReYA6wCbg0y6LMzCw7J2zxR8RO4AngCqAW+FZEtGVcl5mZZeSELX5J/xvYASwDFgFrJP08Iv4s6+LMzOz0K6SP/8GIuD0iWiLi18CVwIFCNi7pHkkbJb0o6d502qclvSBpg6QnJc0/hfrNzGyYCunq+R9DPvdExKdPtJ6kZcCHSM4HXASsknQO8IWIuDAiLgZ+BHzqpCo3M7OTUsiwzJdLek5Sm6QuSb2SCmnxLwUaIqIjInpI7v69OSJaBy1TwVFuDjMzs+wU1NUDvB94BZgEfBD4agHrbQSuklQlqRy4geQcAZI+I2krycBvR23xS7pL0lpJa/fu3VvA7szMrBAFPYErIn4HlEZEb0R8A7i+gHU2AQ+QjOH/BLAB6E3nfTIiFgH1wEeOsf5DEVEXEXWzZs0q6MuYmdmJFRL8HZLGAxskfV7Sxwtcj4hYExErI+JqoBl4ecgi9cB7hlWxmZmdkkIC/LZ0uY8A7STdNQWFtaTZ6Ws1yYNcvi3p3EGL3AS8NJyCzczs1BQyLPOW9O1h4C+Huf3HJVUB3cDdEdEiaU061k8fsAX48DC3aWZmp6CQIRtOWkRcdZRp7toxMyuigvrqzcxs7BhW8Euam1UhZmY2Mobb4v+fmVRhZmYjZrjBr0yqMDOzETPc4H84kyrMzGzEDCv4I6KQoRrMzOwM5qt6zMxyxsFvZpYzhQzL/FFJlSNRjJmZZa+QFv8c4DlJ/13S9ZJ8ZY+Z2ShWyBO4/gI4F1gD3Am8Iumzks7OuDYzM8tAocMrB7Ar/dcDVAKPSfp8hrWZmVkGTjhIm6R7gNuBJuAR4N9GRLekEpKnct2fbYlmZnY6FTI65wySZ+VuGTwxIvokrcqmLDMzy0oh4/H/h+PM23R6yzEzs6z5On4zs5xx8JuZ5YyD38wsZxz8ZmY54+A3M8sZB7+ZWc44+M3McsbBb2aWMw5+M7OccfCbmeWMg9/MLGcc/GZmOePgNzPLGQe/mVnOOPjNzHLGwW9mljMOfjOznHHwm5nljIPfzCxnHPxmZjnj4DczyxkHv5lZzjj4zcxyxsFvZpYzDn4zs5xx8JuZ5YyD38wsZxz8ZmY54+A3M8sZB7+ZWc5kGvyS7pG0UdKLku5Np31B0kuSXpD0fUnTs6zBzMyOlFnwS1oGfAi4FLgIWCXpHOCnwLKIuBB4GfhEVjWYmdnrZdniXwo0RERHRPQATwM3R8ST6WeAZ4CFGdZgZmZDZBn8G4GrJFVJKgduABYNWeYDwE+OtrKkuyStlbR27969GZZpZpYvmQV/RGwCHgCeBJ4ANgC9/fMlfRLoAeqPsf5DEVEXEXWzZs3Kqkwzs9zJ9ORuRKyJiJURcTXQTNKnj6Q7gVXA6oiILGswM7MjlWW5cUmzI2KPpGrgZuBySdcD9wPXRERHlvs3M7PXyzT4gcclVQHdwN0R0SLpQWAC8FNJAM9ExIczrsPMzFKZBn9EXHWUaedkuU8zMzs+37lrZpYzDn4zs5xx8JuZ5YyD38wsZxz8ZmY54+A3M8sZB7+ZWc44+M3McsbBb2aWMw5+M7OccfCbmeWMg9/MLGcc/GZmOePgNzPLGQe/mVnOOPjNzHLGwW9mljMOfjOznHHwm5nljIPfzCxnHPxmZjnj4DczyxkHv5lZzjj4zcxyxsFvZpYzDn4zs5xx8JuZ5YyD38wsZxz8ZmY54+A3M8sZB7+ZWc44+M3McsbBb2aWMw5+M7OccfCbmeWMg9/MLGcc/GZmOePgNzPLGQe/mVnOOPjNzHLGwW9mljMOfjOznHHwm5nljIPfzCxnHPxmZjnj4Dczy5lMg1/SPZI2SnpR0r3ptPemn/sk1WW5fzMze73Mgl/SMuBDwKXARcAqSecAG4GbgZ9ntW8zMzu2LFv8S4GGiOiIiB7gaeDmiNgUEb/NcL9mZnYcZRlueyPwGUlVwCHgBmBtoStLugu4K/3YJulkDxYzgaaTXLfYXHtxjNbaR2vd4NqzUnO0iZkFf0RskvQA8CTQDmwAeoex/kPAQ6dah6S1ETEqzyW49uIYrbWP1rrBtY+0TE/uRsSaiFgZEVcDzcDLWe7PzMxOLMuuHiTNjog9kqpJTuhenuX+zMzsxDINfuDxtI+/G7g7IlokvRv4O2AW8GNJGyLiHRnWcMrdRUXk2otjtNY+WusG1z6iFBHFrsHMzEaQ79w1M8sZB7+ZWc6M2eCXtEjSzyT9Jh0i4p5i1zQckkol/UrSj4pdy3BImi7pMUkvSdok6Ypi11QoSR9Pf1Y2SvqOpInFrulYJD0qaY+kjYOmzZD0U0mvpK+VxazxWI5R+xfSn5kXJH1f0vRi1ngsR6t90Lz7JIWkmcWobTjGbPADPcB9EXE+ydVEd0s6v8g1Dcc9wKZiF3ES/hZ4IiKWkAzVMSq+g6QFwMeAuohYBpQC7ytuVcf1TeD6IdP+HfBURJwLPJV+PhN9k9fX/lNgWURcSHLZ9ydGuqgCfZPX146kRcDbgcaRLuhkjNngj4idEbE+fX+QJIAWFLeqwkhaCLwTeKTYtQyHpGnA1cAagIjoioiW4lY1LGXAJEllQDmwo8j1HFNE/BzYP2TyTcC30vffAt41okUV6Gi1R8ST6dAuAM8AC0e8sAIc4/8d4EvA/cCouFpmzAb/YJJqgeVAQ3ErKdiXSX6I+opdyDCdBewFvpF2Uz0iqaLYRRUiIrYDXyRpse0EDkTEk8WtatjmRMTO9P0uYE4xizkFHwB+UuwiCiXpJmB7RDxf7FoKNeaDX9Jk4HHg3ohoLXY9JyJpFbAnItYVu5aTUAasAL4WEctJhuo4U7sbjpD2h99EcvCaD1RIurW4VZ28SK7THhWtz8EkfZKkm7a+2LUUQlI58OfAp4pdy3CM6eCXNI4k9Osj4nvFrqdAbwRulLQZ+EfgOkn/UNySCrYN2BYR/X9ZPUZyIBgN3gq8GhF7I6Ib+B5wZZFrGq7dkuYBpK97ilzPsEi6E1gFrI7Rc4PR2SSNhefT39mFwHpJc4ta1QmM2eCXJJK+5k0R8TfFrqdQEfGJiFgYEbUkJxf/OSJGRcszInYBWyUtTie9BfhNEUsajkbgcknl6c/OWxglJ6YH+SfgjvT9HcAPiljLsEi6nqR788aI6Ch2PYWKiF9HxOyIqE1/Z7cBK9LfhTPWmA1+kpbzbSQt5g3pvxuKXVQOfBSol/QCcDHw2SLXU5D0r5THgPXAr0l+N87YW/ElfQf4F2CxpG2S/gT4HPA2Sa+Q/AXzuWLWeCzHqP1BYArw0/R39e+LWuQxHKP2UcdDNpiZ5cxYbvGbmdlROPjNzHLGwW9mljMOfjOznHHwm5nljIPfbARIqpP0X4pdhxn4ck4zs9xxi99ySdIl6djvEyVVpOPwLxvG+rWSfiFpffrvynT6uyU9pcQ8SS9Lmivp2v5nK0i6ZtBNhb+SNCWr72l2NG7xW25J+itgIjCJZIyhvx7GuuVAX0QclnQu8J2IqEvn/QPJ0MLXk4wT9R1J1wJ/FhGrJP0Q+FxE/DIdRPDwoCGJzTJXVuwCzIroPwHPAYdJHsIyHOOAByVdDPQC5w2a91FgI/BMRHznKOv+EvgbSfXA9yJi27ArNzsF7uqxPKsCJpOMEfO6xyxKuntQl8z8IbM/DuwmecpYHTB+0LyFJM9SmCPpdb9jEfE54IMkf2n8UtKS0/FlzArl4Lc8+zrw70nGfn9g6MyI+EpEXJz+G/o0rmnAzojoIxkMsBQgfXrXo8D7SUb3/DdDtyvp7HRUxwdI/uJw8NuIcleP5ZKk24HuiPi2pFLg/0q6LiL+ucBNfBV4PN3OEyQPnYHkoRy/iIj/I+l54DlJPx6y7r2S3kzyV8GLjKKnTdnY4JO7ZmY5464eM7OccfCbmeWMg9/MLGcc/GZmOePgNzPLGQe/mVnOOPjNzHLm/wPpvGxl9I3e3gAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSufXze8zmV3"
      },
      "source": [
        "## Part-2\n",
        "Vectorize tweets based on the text. More details and reference links can be checked on the Tasks list in the start of the notebook"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "def remove_usernames_links(text):\n",
        "    text = re.sub('@[^\\s]+','',str(text))\n",
        "    text = re.sub('http[^\\s]+','',str(text))\n",
        "    text = re.sub('#(\\w+)','',str(text))\n",
        "    text = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', str(text))\n",
        "    # remove extra symbols\n",
        "    text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
        "    # remove extra spaces\n",
        "    text = re.sub(' +', ' ', text)\n",
        "    return text"
      ],
      "metadata": {
        "id": "mwg7nfekdNkZ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "def utils_preprocess_text(text, flg_stemm=False, flg_lemm=True, lst_stopwords=None):\n",
        "    ## clean (convert to lowercase and remove punctuations and characters and then strip)\n",
        "    text = re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n",
        "            \n",
        "    ## Tokenize (convert from string to list)\n",
        "    lst_text = text.split()\n",
        "    ## remove Stopwords\n",
        "    if lst_stopwords is not None:\n",
        "        lst_text = [word for word in lst_text if word not in \n",
        "                    lst_stopwords]\n",
        "                \n",
        "    ## Stemming (remove -ing, -ly, ...)\n",
        "    if flg_stemm == True:\n",
        "        ps = nltk.stem.porter.PorterStemmer()\n",
        "        lst_text = [ps.stem(word) for word in lst_text]\n",
        "                \n",
        "    ## Lemmatisation (convert the word into root word)\n",
        "    if flg_lemm == True:\n",
        "        lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
        "        lst_text = [lem.lemmatize(word) for word in lst_text]\n",
        "            \n",
        "    ## back to string from list\n",
        "    text = \" \".join(lst_text)\n",
        "    return text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_J0d9p99pMAW",
        "outputId": "6749fe92-e669-4495-bb02-823e6522c75c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lst_stopwords = nltk.corpus.stopwords.words(\"english\")\n",
        "lst_stopwords"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrrAObRVpW-i",
        "outputId": "d121a41e-cce2-42fe-dab8-2007f35b8257"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'd',\n",
              " 'll',\n",
              " 'm',\n",
              " 'o',\n",
              " 're',\n",
              " 've',\n",
              " 'y',\n",
              " 'ain',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'ma',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\"]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "GBizLGhg0kQT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a3f6a28-94e4-4aaf-ffc0-92eda7ca4519"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "<ipython-input-35-73de83afceab>:15: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  df3['text'] = df3['text'].str.replace('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', ' ')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        th u circuit court appeal upheld lower court r...\n",
              "1               world enough superheroes watch new trailer\n",
              "2                  teacher v student match amp one teacher\n",
              "3        someone office actually responded netflix twee...\n",
              "4        starbucks asking soy milk man behind trying ma...\n",
              "                               ...                        \n",
              "11094    following tabitha johnson green georgia come s...\n",
              "11095    exactly donald trump supposed press openly pos...\n",
              "11096    paradoxically good intention may stand way cap...\n",
              "11097    le day go international blockchain congress wa...\n",
              "11098              nature human wired connectedness pisces\n",
              "Name: text, Length: 11099, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "def tweet_vectoriser():\n",
        "  \"\"\"\n",
        "  Funtion to return a matrix of dimensions (number of tweets, number of features extracted per tweet)\n",
        "  Following are the steps for be followed:\n",
        "    1. Remove links, tags and hashtags from each tweet.\n",
        "    2. Apply TF-IDF on the tweets to extract a vector. \n",
        "    3. Perform dimensionality reduction on the obtained vector. \n",
        "  Input parameters to this funcion are to be chosen as per requirement (Example: Array of tweets) \n",
        "  \"\"\"\n",
        "  # your code here\n",
        "  df3 = pd.read_csv('Tweets.csv')\n",
        "\n",
        "  df3['text'] = df3['text'].str.replace('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', ' ')\n",
        "  df3['text'] = df3['text'].apply(remove_usernames_links)\n",
        "  df3['text'] = df3['text'].str.replace('\\W', ' ', regex=True)\n",
        "  df3['text'] = df3['text'].str.replace('\\d+', ' ', regex=True)\n",
        "  df3['text'] = df3['text'].str.replace('RT', '', regex=True)\n",
        "  # remove all single characters\n",
        "  # print(df3)\n",
        "  df3['text'] = df3['text'].apply(remove_usernames_links)\n",
        "  return df3\n",
        "df4 = tweet_vectoriser()\n",
        "df5 = df4[\"text\"].apply(lambda x: utils_preprocess_text(x, flg_stemm=False, flg_lemm=True, lst_stopwords=lst_stopwords))\n",
        "df5\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Q47SVkv9VzO"
      },
      "source": [
        "Perform KNN using the vector obtained from tweet_vectoriser() function. Following are the steps to be followed:\n",
        "\n",
        "1. Normalise the vectors\n",
        "2. Split the data into training and test to estimate the performance.\n",
        "3. Fit the Nearest Neughbiurs module to the training data and obtain the predicted class by getting the nearest neighbours on the test data.\n",
        "4. Report the accuracy, chosen k-value and method used to obtain the predicted class. Hint: Plot accuracies for a range of k-values."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lWMrgLaL_HGu"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import seaborn as sns\n",
        "from sklearn.feature_selection import SelectPercentile, chi2\n",
        "from sklearn import *\n",
        "## Count (classic BoW)\n",
        "vectorizer = feature_extraction.text.CountVectorizer(max_features=10000, ngram_range=(1,2))\n",
        "\n",
        "## Tf-Idf (advanced variant of BoW)\n",
        "vectorizer = feature_extraction.text.TfidfVectorizer(max_features=10000, ngram_range=(1,2))\n",
        "corpus = df5\n",
        "vectorizer.fit(corpus)\n",
        "X_train = vectorizer.transform(corpus)\n",
        "dic_vocabulary = vectorizer.vocabulary_\n",
        "\n",
        "X = df5\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_ = vectorizer.fit_transform(df5)\n",
        "vectorizer.get_feature_names_out()\n",
        "\n",
        "X1  = TruncatedSVD(n_components=20).fit_transform(X_train)\n",
        "\n",
        "tt = pd.DataFrame(X1)\n",
        "tt=pd.DataFrame(preprocessing.normalize(tt,norm='l2', axis=1))\n",
        "tt.head()\n",
        "tt.describe()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "jHUTSNUmhTqh",
        "outputId": "03094300-b189-46dc-be59-9de24350eecb"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 0             1             2             3             4   \\\n",
              "count  11099.000000  11099.000000  11099.000000  11099.000000  11099.000000   \n",
              "mean       0.093331      0.124199      0.173210     -0.444921     -0.127136   \n",
              "std        0.150816      0.139505      0.114049      0.209995      0.110389   \n",
              "min        0.000000     -0.045662     -0.131932     -0.855508     -0.258905   \n",
              "25%        0.037902      0.065643      0.106789     -0.619167     -0.188602   \n",
              "50%        0.055994      0.097829      0.162995     -0.448068     -0.135944   \n",
              "75%        0.079779      0.135318      0.229124     -0.303600     -0.092125   \n",
              "max        0.993523      0.988908      0.943631      0.343408      0.957711   \n",
              "\n",
              "                 5             6             7             8             9   \\\n",
              "count  11099.000000  11099.000000  11099.000000  11099.000000  11099.000000   \n",
              "mean      -0.018164     -0.006885     -0.027985     -0.025748     -0.050781   \n",
              "std        0.120962      0.111883      0.146080      0.179655      0.214992   \n",
              "min       -0.138970     -0.246359     -0.203698     -0.456931     -0.514733   \n",
              "25%       -0.055477     -0.038990     -0.092898     -0.106859     -0.179633   \n",
              "50%       -0.037620     -0.016383     -0.058510     -0.046634     -0.078026   \n",
              "75%       -0.015913      0.006863     -0.015473      0.008779      0.002923   \n",
              "max        0.992339      0.968466      0.954366      0.826091      0.901331   \n",
              "\n",
              "                 10            11            12            13            14  \\\n",
              "count  11099.000000  11099.000000  11099.000000  11099.000000  11099.000000   \n",
              "mean      -0.089601     -0.030512     -0.007871      0.008393      0.008527   \n",
              "std        0.211813      0.207789      0.207185      0.207558      0.160083   \n",
              "min       -0.504415     -0.568793     -0.696188     -0.698950     -0.481290   \n",
              "25%       -0.221638     -0.157857     -0.120115     -0.119165     -0.068049   \n",
              "50%       -0.122676     -0.047141     -0.017848      0.010286     -0.005272   \n",
              "75%       -0.009889      0.048592      0.071359      0.129785      0.052935   \n",
              "max        0.817094      0.874623      0.811569      0.622888      0.945299   \n",
              "\n",
              "                 15            16            17            18            19  \n",
              "count  11099.000000  11099.000000  11099.000000  11099.000000  11099.000000  \n",
              "mean       0.013694      0.051450     -0.070298      0.008964      0.058147  \n",
              "std        0.204009      0.207708      0.244484      0.168590      0.286063  \n",
              "min       -0.545061     -0.484382     -0.739543     -0.534075     -0.848042  \n",
              "25%       -0.092956     -0.070409     -0.244501     -0.068229     -0.098539  \n",
              "50%        0.001255      0.024021     -0.058519      0.000300      0.035172  \n",
              "75%        0.088196      0.173829      0.094088      0.081734      0.219691  \n",
              "max        0.869135      0.777595      0.781402      0.974753      0.818313  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9deee68c-6647-4a7e-824e-4dcc32c13433\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>11099.000000</td>\n",
              "      <td>11099.000000</td>\n",
              "      <td>11099.000000</td>\n",
              "      <td>11099.000000</td>\n",
              "      <td>11099.000000</td>\n",
              "      <td>11099.000000</td>\n",
              "      <td>11099.000000</td>\n",
              "      <td>11099.000000</td>\n",
              "      <td>11099.000000</td>\n",
              "      <td>11099.000000</td>\n",
              "      <td>11099.000000</td>\n",
              "      <td>11099.000000</td>\n",
              "      <td>11099.000000</td>\n",
              "      <td>11099.000000</td>\n",
              "      <td>11099.000000</td>\n",
              "      <td>11099.000000</td>\n",
              "      <td>11099.000000</td>\n",
              "      <td>11099.000000</td>\n",
              "      <td>11099.000000</td>\n",
              "      <td>11099.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.093331</td>\n",
              "      <td>0.124199</td>\n",
              "      <td>0.173210</td>\n",
              "      <td>-0.444921</td>\n",
              "      <td>-0.127136</td>\n",
              "      <td>-0.018164</td>\n",
              "      <td>-0.006885</td>\n",
              "      <td>-0.027985</td>\n",
              "      <td>-0.025748</td>\n",
              "      <td>-0.050781</td>\n",
              "      <td>-0.089601</td>\n",
              "      <td>-0.030512</td>\n",
              "      <td>-0.007871</td>\n",
              "      <td>0.008393</td>\n",
              "      <td>0.008527</td>\n",
              "      <td>0.013694</td>\n",
              "      <td>0.051450</td>\n",
              "      <td>-0.070298</td>\n",
              "      <td>0.008964</td>\n",
              "      <td>0.058147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.150816</td>\n",
              "      <td>0.139505</td>\n",
              "      <td>0.114049</td>\n",
              "      <td>0.209995</td>\n",
              "      <td>0.110389</td>\n",
              "      <td>0.120962</td>\n",
              "      <td>0.111883</td>\n",
              "      <td>0.146080</td>\n",
              "      <td>0.179655</td>\n",
              "      <td>0.214992</td>\n",
              "      <td>0.211813</td>\n",
              "      <td>0.207789</td>\n",
              "      <td>0.207185</td>\n",
              "      <td>0.207558</td>\n",
              "      <td>0.160083</td>\n",
              "      <td>0.204009</td>\n",
              "      <td>0.207708</td>\n",
              "      <td>0.244484</td>\n",
              "      <td>0.168590</td>\n",
              "      <td>0.286063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.045662</td>\n",
              "      <td>-0.131932</td>\n",
              "      <td>-0.855508</td>\n",
              "      <td>-0.258905</td>\n",
              "      <td>-0.138970</td>\n",
              "      <td>-0.246359</td>\n",
              "      <td>-0.203698</td>\n",
              "      <td>-0.456931</td>\n",
              "      <td>-0.514733</td>\n",
              "      <td>-0.504415</td>\n",
              "      <td>-0.568793</td>\n",
              "      <td>-0.696188</td>\n",
              "      <td>-0.698950</td>\n",
              "      <td>-0.481290</td>\n",
              "      <td>-0.545061</td>\n",
              "      <td>-0.484382</td>\n",
              "      <td>-0.739543</td>\n",
              "      <td>-0.534075</td>\n",
              "      <td>-0.848042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.037902</td>\n",
              "      <td>0.065643</td>\n",
              "      <td>0.106789</td>\n",
              "      <td>-0.619167</td>\n",
              "      <td>-0.188602</td>\n",
              "      <td>-0.055477</td>\n",
              "      <td>-0.038990</td>\n",
              "      <td>-0.092898</td>\n",
              "      <td>-0.106859</td>\n",
              "      <td>-0.179633</td>\n",
              "      <td>-0.221638</td>\n",
              "      <td>-0.157857</td>\n",
              "      <td>-0.120115</td>\n",
              "      <td>-0.119165</td>\n",
              "      <td>-0.068049</td>\n",
              "      <td>-0.092956</td>\n",
              "      <td>-0.070409</td>\n",
              "      <td>-0.244501</td>\n",
              "      <td>-0.068229</td>\n",
              "      <td>-0.098539</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.055994</td>\n",
              "      <td>0.097829</td>\n",
              "      <td>0.162995</td>\n",
              "      <td>-0.448068</td>\n",
              "      <td>-0.135944</td>\n",
              "      <td>-0.037620</td>\n",
              "      <td>-0.016383</td>\n",
              "      <td>-0.058510</td>\n",
              "      <td>-0.046634</td>\n",
              "      <td>-0.078026</td>\n",
              "      <td>-0.122676</td>\n",
              "      <td>-0.047141</td>\n",
              "      <td>-0.017848</td>\n",
              "      <td>0.010286</td>\n",
              "      <td>-0.005272</td>\n",
              "      <td>0.001255</td>\n",
              "      <td>0.024021</td>\n",
              "      <td>-0.058519</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>0.035172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.079779</td>\n",
              "      <td>0.135318</td>\n",
              "      <td>0.229124</td>\n",
              "      <td>-0.303600</td>\n",
              "      <td>-0.092125</td>\n",
              "      <td>-0.015913</td>\n",
              "      <td>0.006863</td>\n",
              "      <td>-0.015473</td>\n",
              "      <td>0.008779</td>\n",
              "      <td>0.002923</td>\n",
              "      <td>-0.009889</td>\n",
              "      <td>0.048592</td>\n",
              "      <td>0.071359</td>\n",
              "      <td>0.129785</td>\n",
              "      <td>0.052935</td>\n",
              "      <td>0.088196</td>\n",
              "      <td>0.173829</td>\n",
              "      <td>0.094088</td>\n",
              "      <td>0.081734</td>\n",
              "      <td>0.219691</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.993523</td>\n",
              "      <td>0.988908</td>\n",
              "      <td>0.943631</td>\n",
              "      <td>0.343408</td>\n",
              "      <td>0.957711</td>\n",
              "      <td>0.992339</td>\n",
              "      <td>0.968466</td>\n",
              "      <td>0.954366</td>\n",
              "      <td>0.826091</td>\n",
              "      <td>0.901331</td>\n",
              "      <td>0.817094</td>\n",
              "      <td>0.874623</td>\n",
              "      <td>0.811569</td>\n",
              "      <td>0.622888</td>\n",
              "      <td>0.945299</td>\n",
              "      <td>0.869135</td>\n",
              "      <td>0.777595</td>\n",
              "      <td>0.781402</td>\n",
              "      <td>0.974753</td>\n",
              "      <td>0.818313</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9deee68c-6647-4a7e-824e-4dcc32c13433')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9deee68c-6647-4a7e-824e-4dcc32c13433 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9deee68c-6647-4a7e-824e-4dcc32c13433');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y = pd.read_csv('ground_truth.csv')\n",
        "X = tt.iloc[:,:].values\n",
        "Y = Y.iloc[:,:].values\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.33,random_state=0)\n",
        "model = K_Nearest_Neighbors_Classifier( K = 3 )\n",
        "model.fit( x_train, y_train )\n",
        "print(x_train)\n",
        "Y_pred = model.predict( x_test )\n",
        "correctly_classified = 0\n",
        "count = 0\n",
        "for count in range( np.size( Y_pred ) ) :\n",
        "    if y_test[count] == Y_pred[count] :\n",
        "        correctly_classified = correctly_classified + 1\n",
        "    count = count + 1\n",
        "print( \"Accuracy on test set by our model       :  \", (correctly_classified / count ) * 100 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NIq2BsmRAWS",
        "outputId": "1ec21686-0dac-46c4-e384-d92214f01dc4"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.30746741  0.04718847  0.09062731 ... -0.48049214  0.12510923\n",
            "   0.00104867]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.07610531  0.13251768  0.21242704 ... -0.30441274  0.08781053\n",
            "   0.49845044]\n",
            " ...\n",
            " [ 0.05349729  0.11598742  0.18200227 ... -0.14324336  0.13741769\n",
            "  -0.37789559]\n",
            " [ 0.0413751   0.07524687  0.11556815 ... -0.38713374 -0.01259371\n",
            "   0.34992996]\n",
            " [ 0.06942511  0.13166526  0.23463248 ... -0.40837596 -0.02428911\n",
            "   0.09191248]]\n",
            "Accuracy on test set by our model       :   92.001092001092\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k_val = [2,3,5,8,11,15]\n",
        "accu = []\n",
        "for i in k_val:\n",
        "  model = K_Nearest_Neighbors_Classifier( K = i )\n",
        "  model.fit( x_train, y_train )\n",
        "  Y_pred = model.predict( x_test )\n",
        "  correctly_classified = 0\n",
        "  count = 0\n",
        "  for count in range( np.size( Y_pred ) ) :\n",
        "      if y_test[count] == Y_pred[count] :\n",
        "          correctly_classified = correctly_classified + 1\n",
        "      count = count + 1\n",
        "  print( \"Accuracy on test set by our model       :  \", (correctly_classified / count ) * 100 )\n",
        "  accu.append((correctly_classified / count ) * 100)\n",
        "print(accu)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AaOfhoSOlkQt",
        "outputId": "35bdd237-a326-4c8b-e701-eaf766c333f2"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on test set by our model       :   92.57439257439258\n",
            "Accuracy on test set by our model       :   92.001092001092\n",
            "Accuracy on test set by our model       :   92.35599235599236\n",
            "Accuracy on test set by our model       :   92.71089271089271\n",
            "Accuracy on test set by our model       :   92.71089271089271\n",
            "Accuracy on test set by our model       :   92.54709254709255\n",
            "[92.57439257439258, 92.001092001092, 92.35599235599236, 92.71089271089271, 92.71089271089271, 92.54709254709255]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt \n",
        "plt.plot(k_val, accu) \n",
        "# naming the x axis \n",
        "plt.xlabel('x - axis') \n",
        "# naming the y axis \n",
        "plt.ylabel('y - axis') \n",
        "plt.yticks(list(range(91, 96, 1)))\n",
        "    \n",
        "# function to show the plot \n",
        "plt.show() "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "7nUDo5d3lpnz",
        "outputId": "c435e6c9-f099-40f2-b8f4-6c43ea185ece"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rg7hD8-O3PbO"
      },
      "source": [
        "## Part-3\n",
        "### Subpart-1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bp9TVeVD9lKe"
      },
      "source": [
        "Combine both the vectors obtained from the tweet_vectoriser() and get_features()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "r5ksyj7_3_xl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 974
        },
        "outputId": "047e35ef-41d3-4da7-e797-0cd7e7f93c55"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "             0    1         2         3         4         5         6   \\\n",
              "0      0.002485  0.0  0.003364  0.005805  0.000154  0.725275  0.688422   \n",
              "1      0.067276  0.0  0.008891  0.004354  0.000137  0.075780  0.994803   \n",
              "2      0.548672  0.0  0.037360  0.036041  0.000147  0.794952  0.253605   \n",
              "3      0.001383  0.0  0.334497  0.335741  0.000553  0.828706  0.297715   \n",
              "4      0.595977  0.0  0.007395  0.017004  0.000165  0.148017  0.789024   \n",
              "...         ...  ...       ...       ...       ...       ...       ...   \n",
              "11094  0.000063  0.0  0.010097  0.017034  0.000088  0.996459  0.081719   \n",
              "11095  0.836143  0.0  0.042739  0.059675  0.001195  0.202137  0.504595   \n",
              "11096  0.000000  0.0  0.031622  0.022019  0.000000  0.021082  0.999035   \n",
              "11097  0.000862  0.0  0.024187  0.011638  0.000383  0.758123  0.651558   \n",
              "11098  0.000000  0.0  0.025285  0.047499  0.000214  0.004571  0.998541   \n",
              "\n",
              "             0         1         2   ...        10        11        12  \\\n",
              "0      0.068668  0.129351  0.237241  ... -0.070641 -0.431199  0.184534   \n",
              "1      0.993697 -0.045691 -0.049375  ...  0.004368 -0.008722 -0.004211   \n",
              "2      0.038057  0.072013  0.309021  ...  0.014204 -0.127968  0.554919   \n",
              "3      0.065625  0.113276  0.193700  ...  0.158905 -0.071769 -0.098479   \n",
              "4      0.019214  0.037762  0.062119  ... -0.094924 -0.011398 -0.185560   \n",
              "...         ...       ...       ...  ...       ...       ...       ...   \n",
              "11094  0.096851  0.176407  0.301197  ... -0.058503  0.092512  0.301115   \n",
              "11095  0.021603  0.051869  0.091339  ... -0.193715 -0.222365  0.067590   \n",
              "11096  0.024642  0.978614 -0.131957  ...  0.010659  0.000940  0.006846   \n",
              "11097  0.364847  0.073480  0.121394  ...  0.357761 -0.126029 -0.149759   \n",
              "11098  0.002066  0.004428  0.009882  ...  0.002034  0.003535 -0.003087   \n",
              "\n",
              "             13        14            15        16        17        18  \\\n",
              "0      0.042400 -0.078407  5.325931e-03  0.067564 -0.080841  0.046326   \n",
              "1     -0.003447 -0.004905  3.861003e-03  0.005220  0.000042 -0.002916   \n",
              "2      0.179844 -0.020220 -4.829201e-01 -0.211944 -0.027325  0.205905   \n",
              "3      0.080882 -0.127455  1.007503e-01 -0.038203 -0.015459 -0.183369   \n",
              "4     -0.290936  0.498770 -1.833064e-01  0.300630  0.284944 -0.527178   \n",
              "...         ...       ...           ...       ...       ...       ...   \n",
              "11094 -0.036082 -0.004182 -2.068319e-01  0.223267 -0.097604 -0.093977   \n",
              "11095  0.044052  0.009915  5.059821e-01 -0.029063 -0.598914  0.041930   \n",
              "11096  0.004173 -0.000875 -1.610817e-03  0.004486  0.001506  0.000732   \n",
              "11097  0.026820 -0.026737 -6.518180e-03 -0.041966  0.012479 -0.055922   \n",
              "11098 -0.001262 -0.001631  5.436321e-07  0.001585  0.000204 -0.000295   \n",
              "\n",
              "             19  \n",
              "0      0.231259  \n",
              "1     -0.001509  \n",
              "2     -0.086977  \n",
              "3     -0.281545  \n",
              "4      0.304248  \n",
              "...         ...  \n",
              "11094 -0.006318  \n",
              "11095 -0.427890  \n",
              "11096  0.008476  \n",
              "11097 -0.071057  \n",
              "11098 -0.000648  \n",
              "\n",
              "[11099 rows x 27 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ead2bf02-8084-467b-bf9b-b5d4dff29003\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>...</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.002485</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003364</td>\n",
              "      <td>0.005805</td>\n",
              "      <td>0.000154</td>\n",
              "      <td>0.725275</td>\n",
              "      <td>0.688422</td>\n",
              "      <td>0.068668</td>\n",
              "      <td>0.129351</td>\n",
              "      <td>0.237241</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.070641</td>\n",
              "      <td>-0.431199</td>\n",
              "      <td>0.184534</td>\n",
              "      <td>0.042400</td>\n",
              "      <td>-0.078407</td>\n",
              "      <td>5.325931e-03</td>\n",
              "      <td>0.067564</td>\n",
              "      <td>-0.080841</td>\n",
              "      <td>0.046326</td>\n",
              "      <td>0.231259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.067276</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008891</td>\n",
              "      <td>0.004354</td>\n",
              "      <td>0.000137</td>\n",
              "      <td>0.075780</td>\n",
              "      <td>0.994803</td>\n",
              "      <td>0.993697</td>\n",
              "      <td>-0.045691</td>\n",
              "      <td>-0.049375</td>\n",
              "      <td>...</td>\n",
              "      <td>0.004368</td>\n",
              "      <td>-0.008722</td>\n",
              "      <td>-0.004211</td>\n",
              "      <td>-0.003447</td>\n",
              "      <td>-0.004905</td>\n",
              "      <td>3.861003e-03</td>\n",
              "      <td>0.005220</td>\n",
              "      <td>0.000042</td>\n",
              "      <td>-0.002916</td>\n",
              "      <td>-0.001509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.548672</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.037360</td>\n",
              "      <td>0.036041</td>\n",
              "      <td>0.000147</td>\n",
              "      <td>0.794952</td>\n",
              "      <td>0.253605</td>\n",
              "      <td>0.038057</td>\n",
              "      <td>0.072013</td>\n",
              "      <td>0.309021</td>\n",
              "      <td>...</td>\n",
              "      <td>0.014204</td>\n",
              "      <td>-0.127968</td>\n",
              "      <td>0.554919</td>\n",
              "      <td>0.179844</td>\n",
              "      <td>-0.020220</td>\n",
              "      <td>-4.829201e-01</td>\n",
              "      <td>-0.211944</td>\n",
              "      <td>-0.027325</td>\n",
              "      <td>0.205905</td>\n",
              "      <td>-0.086977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.001383</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.334497</td>\n",
              "      <td>0.335741</td>\n",
              "      <td>0.000553</td>\n",
              "      <td>0.828706</td>\n",
              "      <td>0.297715</td>\n",
              "      <td>0.065625</td>\n",
              "      <td>0.113276</td>\n",
              "      <td>0.193700</td>\n",
              "      <td>...</td>\n",
              "      <td>0.158905</td>\n",
              "      <td>-0.071769</td>\n",
              "      <td>-0.098479</td>\n",
              "      <td>0.080882</td>\n",
              "      <td>-0.127455</td>\n",
              "      <td>1.007503e-01</td>\n",
              "      <td>-0.038203</td>\n",
              "      <td>-0.015459</td>\n",
              "      <td>-0.183369</td>\n",
              "      <td>-0.281545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.595977</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.007395</td>\n",
              "      <td>0.017004</td>\n",
              "      <td>0.000165</td>\n",
              "      <td>0.148017</td>\n",
              "      <td>0.789024</td>\n",
              "      <td>0.019214</td>\n",
              "      <td>0.037762</td>\n",
              "      <td>0.062119</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.094924</td>\n",
              "      <td>-0.011398</td>\n",
              "      <td>-0.185560</td>\n",
              "      <td>-0.290936</td>\n",
              "      <td>0.498770</td>\n",
              "      <td>-1.833064e-01</td>\n",
              "      <td>0.300630</td>\n",
              "      <td>0.284944</td>\n",
              "      <td>-0.527178</td>\n",
              "      <td>0.304248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11094</th>\n",
              "      <td>0.000063</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.010097</td>\n",
              "      <td>0.017034</td>\n",
              "      <td>0.000088</td>\n",
              "      <td>0.996459</td>\n",
              "      <td>0.081719</td>\n",
              "      <td>0.096851</td>\n",
              "      <td>0.176407</td>\n",
              "      <td>0.301197</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.058503</td>\n",
              "      <td>0.092512</td>\n",
              "      <td>0.301115</td>\n",
              "      <td>-0.036082</td>\n",
              "      <td>-0.004182</td>\n",
              "      <td>-2.068319e-01</td>\n",
              "      <td>0.223267</td>\n",
              "      <td>-0.097604</td>\n",
              "      <td>-0.093977</td>\n",
              "      <td>-0.006318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11095</th>\n",
              "      <td>0.836143</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.042739</td>\n",
              "      <td>0.059675</td>\n",
              "      <td>0.001195</td>\n",
              "      <td>0.202137</td>\n",
              "      <td>0.504595</td>\n",
              "      <td>0.021603</td>\n",
              "      <td>0.051869</td>\n",
              "      <td>0.091339</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.193715</td>\n",
              "      <td>-0.222365</td>\n",
              "      <td>0.067590</td>\n",
              "      <td>0.044052</td>\n",
              "      <td>0.009915</td>\n",
              "      <td>5.059821e-01</td>\n",
              "      <td>-0.029063</td>\n",
              "      <td>-0.598914</td>\n",
              "      <td>0.041930</td>\n",
              "      <td>-0.427890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11096</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.031622</td>\n",
              "      <td>0.022019</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.021082</td>\n",
              "      <td>0.999035</td>\n",
              "      <td>0.024642</td>\n",
              "      <td>0.978614</td>\n",
              "      <td>-0.131957</td>\n",
              "      <td>...</td>\n",
              "      <td>0.010659</td>\n",
              "      <td>0.000940</td>\n",
              "      <td>0.006846</td>\n",
              "      <td>0.004173</td>\n",
              "      <td>-0.000875</td>\n",
              "      <td>-1.610817e-03</td>\n",
              "      <td>0.004486</td>\n",
              "      <td>0.001506</td>\n",
              "      <td>0.000732</td>\n",
              "      <td>0.008476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11097</th>\n",
              "      <td>0.000862</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.024187</td>\n",
              "      <td>0.011638</td>\n",
              "      <td>0.000383</td>\n",
              "      <td>0.758123</td>\n",
              "      <td>0.651558</td>\n",
              "      <td>0.364847</td>\n",
              "      <td>0.073480</td>\n",
              "      <td>0.121394</td>\n",
              "      <td>...</td>\n",
              "      <td>0.357761</td>\n",
              "      <td>-0.126029</td>\n",
              "      <td>-0.149759</td>\n",
              "      <td>0.026820</td>\n",
              "      <td>-0.026737</td>\n",
              "      <td>-6.518180e-03</td>\n",
              "      <td>-0.041966</td>\n",
              "      <td>0.012479</td>\n",
              "      <td>-0.055922</td>\n",
              "      <td>-0.071057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11098</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.025285</td>\n",
              "      <td>0.047499</td>\n",
              "      <td>0.000214</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>0.998541</td>\n",
              "      <td>0.002066</td>\n",
              "      <td>0.004428</td>\n",
              "      <td>0.009882</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002034</td>\n",
              "      <td>0.003535</td>\n",
              "      <td>-0.003087</td>\n",
              "      <td>-0.001262</td>\n",
              "      <td>-0.001631</td>\n",
              "      <td>5.436321e-07</td>\n",
              "      <td>0.001585</td>\n",
              "      <td>0.000204</td>\n",
              "      <td>-0.000295</td>\n",
              "      <td>-0.000648</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11099 rows Ã— 27 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ead2bf02-8084-467b-bf9b-b5d4dff29003')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ead2bf02-8084-467b-bf9b-b5d4dff29003 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ead2bf02-8084-467b-bf9b-b5d4dff29003');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 0             1             2             3             4   \\\n",
              "count  11099.000000  11099.000000  11099.000000  11099.000000  11099.000000   \n",
              "mean       0.070926      0.000017      0.057656      0.066094      0.001004   \n",
              "std        0.173427      0.001233      0.109138      0.115426      0.004073   \n",
              "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "25%        0.000000      0.000000      0.006694      0.007635      0.000000   \n",
              "50%        0.000499      0.000000      0.017291      0.021205      0.000111   \n",
              "75%        0.020095      0.000000      0.050367      0.062248      0.000513   \n",
              "max        0.999975      0.129099      0.737019      0.788336      0.163261   \n",
              "\n",
              "                 5             6             7             8             9   \\\n",
              "count  11099.000000  11099.000000  11099.000000  11099.000000  11099.000000   \n",
              "mean       0.339321      0.471003      0.065086      0.088312      0.122953   \n",
              "std        0.237989      0.212995      0.103099      0.098461      0.080155   \n",
              "min        0.000000      0.000081     -0.000106     -0.032515     -0.093308   \n",
              "25%        0.106040      0.308292      0.027262      0.046659      0.075621   \n",
              "50%        0.348045      0.512735      0.039671      0.070122      0.117457   \n",
              "75%        0.558246      0.669910      0.056308      0.095804      0.162848   \n",
              "max        0.993574      0.999998      0.703679      0.699123      0.659512   \n",
              "\n",
              "       ...            17            18            19            20  \\\n",
              "count  ...  11099.000000  11099.000000  11099.000000  11099.000000   \n",
              "mean   ...     -0.073310     -0.033474     -0.002178     -0.006400   \n",
              "std    ...      0.161239      0.143285      0.153085      0.144392   \n",
              "min    ...     -0.430949     -0.374117     -0.370270     -0.458999   \n",
              "25%    ...     -0.191486     -0.132084     -0.095308     -0.094799   \n",
              "50%    ...     -0.103347     -0.047880     -0.013142     -0.006054   \n",
              "75%    ...      0.002997      0.022811      0.060272      0.068199   \n",
              "max    ...      0.520785      0.616005      0.581892      0.494132   \n",
              "\n",
              "                 21            22            23            24            25  \\\n",
              "count  11099.000000  11099.000000  11099.000000  11099.000000  11099.000000   \n",
              "mean       0.003494      0.026620      0.031007     -0.055252     -0.018555   \n",
              "std        0.117448      0.143537      0.135278      0.160462      0.163424   \n",
              "min       -0.255432     -0.410107     -0.395143     -0.539314     -0.581776   \n",
              "25%       -0.066572     -0.047620     -0.056609     -0.165029     -0.114923   \n",
              "50%       -0.003777      0.014169      0.015552     -0.045663     -0.000637   \n",
              "75%        0.045567      0.103340      0.097766      0.044468      0.081253   \n",
              "max        0.616834      0.506259      0.600890      0.443523      0.545708   \n",
              "\n",
              "                 26  \n",
              "count  11099.000000  \n",
              "mean      -0.004071  \n",
              "std        0.177003  \n",
              "min       -0.577860  \n",
              "25%       -0.099542  \n",
              "50%       -0.001471  \n",
              "75%        0.086469  \n",
              "max        0.571300  \n",
              "\n",
              "[8 rows x 27 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dd77915c-7b98-4dbb-a2ee-16e619c39016\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>11099.000000</td>\n",
              "      <td>11099.000000</td>\n",
              "      <td>11099.000000</td>\n",
              "      <td>11099.000000</td>\n",
              "      <td>11099.000000</td>\n",
              "      <td>11099.000000</td>\n",
              "      <td>11099.000000</td>\n",
              "      <td>11099.000000</td>\n",
              "      <td>11099.000000</td>\n",
              "      <td>11099.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>11099.000000</td>\n",
              "      <td>11099.000000</td>\n",
              "      <td>11099.000000</td>\n",
              "      <td>11099.000000</td>\n",
              "      <td>11099.000000</td>\n",
              "      <td>11099.000000</td>\n",
              "      <td>11099.000000</td>\n",
              "      <td>11099.000000</td>\n",
              "      <td>11099.000000</td>\n",
              "      <td>11099.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.070926</td>\n",
              "      <td>0.000017</td>\n",
              "      <td>0.057656</td>\n",
              "      <td>0.066094</td>\n",
              "      <td>0.001004</td>\n",
              "      <td>0.339321</td>\n",
              "      <td>0.471003</td>\n",
              "      <td>0.065086</td>\n",
              "      <td>0.088312</td>\n",
              "      <td>0.122953</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.073310</td>\n",
              "      <td>-0.033474</td>\n",
              "      <td>-0.002178</td>\n",
              "      <td>-0.006400</td>\n",
              "      <td>0.003494</td>\n",
              "      <td>0.026620</td>\n",
              "      <td>0.031007</td>\n",
              "      <td>-0.055252</td>\n",
              "      <td>-0.018555</td>\n",
              "      <td>-0.004071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.173427</td>\n",
              "      <td>0.001233</td>\n",
              "      <td>0.109138</td>\n",
              "      <td>0.115426</td>\n",
              "      <td>0.004073</td>\n",
              "      <td>0.237989</td>\n",
              "      <td>0.212995</td>\n",
              "      <td>0.103099</td>\n",
              "      <td>0.098461</td>\n",
              "      <td>0.080155</td>\n",
              "      <td>...</td>\n",
              "      <td>0.161239</td>\n",
              "      <td>0.143285</td>\n",
              "      <td>0.153085</td>\n",
              "      <td>0.144392</td>\n",
              "      <td>0.117448</td>\n",
              "      <td>0.143537</td>\n",
              "      <td>0.135278</td>\n",
              "      <td>0.160462</td>\n",
              "      <td>0.163424</td>\n",
              "      <td>0.177003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000081</td>\n",
              "      <td>-0.000106</td>\n",
              "      <td>-0.032515</td>\n",
              "      <td>-0.093308</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.430949</td>\n",
              "      <td>-0.374117</td>\n",
              "      <td>-0.370270</td>\n",
              "      <td>-0.458999</td>\n",
              "      <td>-0.255432</td>\n",
              "      <td>-0.410107</td>\n",
              "      <td>-0.395143</td>\n",
              "      <td>-0.539314</td>\n",
              "      <td>-0.581776</td>\n",
              "      <td>-0.577860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006694</td>\n",
              "      <td>0.007635</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.106040</td>\n",
              "      <td>0.308292</td>\n",
              "      <td>0.027262</td>\n",
              "      <td>0.046659</td>\n",
              "      <td>0.075621</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.191486</td>\n",
              "      <td>-0.132084</td>\n",
              "      <td>-0.095308</td>\n",
              "      <td>-0.094799</td>\n",
              "      <td>-0.066572</td>\n",
              "      <td>-0.047620</td>\n",
              "      <td>-0.056609</td>\n",
              "      <td>-0.165029</td>\n",
              "      <td>-0.114923</td>\n",
              "      <td>-0.099542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000499</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.017291</td>\n",
              "      <td>0.021205</td>\n",
              "      <td>0.000111</td>\n",
              "      <td>0.348045</td>\n",
              "      <td>0.512735</td>\n",
              "      <td>0.039671</td>\n",
              "      <td>0.070122</td>\n",
              "      <td>0.117457</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.103347</td>\n",
              "      <td>-0.047880</td>\n",
              "      <td>-0.013142</td>\n",
              "      <td>-0.006054</td>\n",
              "      <td>-0.003777</td>\n",
              "      <td>0.014169</td>\n",
              "      <td>0.015552</td>\n",
              "      <td>-0.045663</td>\n",
              "      <td>-0.000637</td>\n",
              "      <td>-0.001471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.020095</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.050367</td>\n",
              "      <td>0.062248</td>\n",
              "      <td>0.000513</td>\n",
              "      <td>0.558246</td>\n",
              "      <td>0.669910</td>\n",
              "      <td>0.056308</td>\n",
              "      <td>0.095804</td>\n",
              "      <td>0.162848</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002997</td>\n",
              "      <td>0.022811</td>\n",
              "      <td>0.060272</td>\n",
              "      <td>0.068199</td>\n",
              "      <td>0.045567</td>\n",
              "      <td>0.103340</td>\n",
              "      <td>0.097766</td>\n",
              "      <td>0.044468</td>\n",
              "      <td>0.081253</td>\n",
              "      <td>0.086469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.999975</td>\n",
              "      <td>0.129099</td>\n",
              "      <td>0.737019</td>\n",
              "      <td>0.788336</td>\n",
              "      <td>0.163261</td>\n",
              "      <td>0.993574</td>\n",
              "      <td>0.999998</td>\n",
              "      <td>0.703679</td>\n",
              "      <td>0.699123</td>\n",
              "      <td>0.659512</td>\n",
              "      <td>...</td>\n",
              "      <td>0.520785</td>\n",
              "      <td>0.616005</td>\n",
              "      <td>0.581892</td>\n",
              "      <td>0.494132</td>\n",
              "      <td>0.616834</td>\n",
              "      <td>0.506259</td>\n",
              "      <td>0.600890</td>\n",
              "      <td>0.443523</td>\n",
              "      <td>0.545708</td>\n",
              "      <td>0.571300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows Ã— 27 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dd77915c-7b98-4dbb-a2ee-16e619c39016')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dd77915c-7b98-4dbb-a2ee-16e619c39016 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dd77915c-7b98-4dbb-a2ee-16e619c39016');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "# your code here\n",
        "result = pd.concat([df, tt], axis=1, join='inner')\n",
        "display(result)\n",
        "result=pd.DataFrame(preprocessing.normalize(result,norm='l2', axis=1))\n",
        "result.head()\n",
        "result.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swCD5Jp69xo5"
      },
      "source": [
        "Perform KNN using the vector obtained in the previous step. Following are the steps to be followed:\n",
        "\n",
        "1. Normalise the vectors\n",
        "2. Split the data into training and test to estimate the performance.\n",
        "3. Fit the Nearest Neughbiurs module to the training data and obtain the predicted class by getting the nearest neighbours on the test data.\n",
        "4. Report the accuracy, chosen k-value and method used to obtain the predicted class. Hint: Plot accuracies for a range of k-values."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = result.iloc[:,:].values\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.33,random_state=0)\n",
        "model = K_Nearest_Neighbors_Classifier( K = 3 )\n",
        "model.fit( x_train, y_train )\n",
        "Y_pred = model.predict( x_test )\n",
        "correctly_classified = 0\n",
        "count = 0\n",
        "for count in range( np.size( Y_pred ) ) :\n",
        "    if y_test[count] == Y_pred[count] :\n",
        "        correctly_classified = correctly_classified + 1\n",
        "    count = count + 1\n",
        "print( \"Accuracy on test set by our model       :  \", (correctly_classified / count ) * 100 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLDod9QdEiDn",
        "outputId": "53067a14-45ce-413a-c34a-8d18d7c4325f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on test set by our model       :   93.72099372099372\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k_val = [2,3,5,8,11,15]\n",
        "accu = []\n",
        "for i in k_val:\n",
        "  model = K_Nearest_Neighbors_Classifier( K = i )\n",
        "  model.fit( x_train, y_train )\n",
        "  Y_pred = model.predict( x_test )\n",
        "  correctly_classified = 0\n",
        "  count = 0\n",
        "  for count in range( np.size( Y_pred ) ) :\n",
        "      if y_test[count] == Y_pred[count] :\n",
        "          correctly_classified = correctly_classified + 1\n",
        "      count = count + 1\n",
        "  print( \"Accuracy on test set by our model       :  \", (correctly_classified / count ) * 100 )\n",
        "  accu.append((correctly_classified / count ) * 100)\n",
        "print(accu)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7beG9pDzLUGv",
        "outputId": "317fd5bf-50b9-448e-f9da-417bfbee1cd4"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on test set by our model       :   93.52989352989353\n",
            "Accuracy on test set by our model       :   93.72099372099372\n",
            "Accuracy on test set by our model       :   93.3933933933934\n",
            "Accuracy on test set by our model       :   93.31149331149331\n",
            "Accuracy on test set by our model       :   93.44799344799345\n",
            "Accuracy on test set by our model       :   93.42069342069342\n",
            "[93.52989352989353, 93.72099372099372, 93.3933933933934, 93.31149331149331, 93.44799344799345, 93.42069342069342]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt \n",
        "plt.plot(k_val, accu) \n",
        "# naming the x axis \n",
        "plt.xlabel('x - axis') \n",
        "# naming the y axis \n",
        "plt.ylabel('y - axis') \n",
        "plt.yticks(list(range(91, 96, 1)))\n",
        "    \n",
        "# function to show the plot \n",
        "plt.show() "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "dTlXkJP7f0bM",
        "outputId": "9c5686c5-e2bf-45ec-9c7b-a613158157ce"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NVQLLhE3c79"
      },
      "source": [
        "### Subpart-2\n",
        "\n",
        "Explain the differences between the accuracies obtained in each part above based on the features used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "rufknWgo4AvY"
      },
      "outputs": [],
      "source": [
        "# your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkiTeqaE_4ic"
      },
      "source": [
        "In First part we considered only integeral values\n",
        "\n",
        "Accuracy Obtained : 94.72972972972973\n",
        "\n",
        "In Second Part we considered only text field \n",
        "\n",
        "Accuracy Obtained : 92.71089271089271\n",
        "\n",
        "In Third part we took the combination of both\n",
        "\n",
        "Accuracy Obtained : 93.72099372099372"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}